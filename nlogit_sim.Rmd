nlogit posteestimation
- calculates choice probabilities 
- calcaluates logsums 

# Setup
```{r setup, include = FALSE}
  rm(list = ls())

knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE, cache = TRUE, fig.align = 'center', fig.width = 10, fig.height = 7) 

# libraries
library(tidyverse)
library(readxl)
library(magrittr)
library(MASS)
library(matrixStats)
library(dplyr)
library(data.table)
library(gtable)
library(gridExtra)
library(sp)
library(raster)
library(rgeos)
library(rgdal)
library(sf)

# simulation 
model <- "nex" #'[#NOTE: choose model] 
sim <- "sim4" #'[#NOTE: choose simulation] 
cost <- "fcflt_spgam"  #'[#NOTE: choose cost variable] # not needed for attatasc

b <- read_excel(paste0("./data/03_data/", model, ".xlsx")) # coefs for model (marginal utilities)
a <- nrow(b) + 2
v <- read_excel(paste0("./data/03_data/", model, ".xlsx"), sheet = "v", col_names = rep("x", a)) %>% distinct()

# NEX RUMN paper
dat <- read_csv(paste0("./data/02_data/2.1_nex_", sim, ".csv")) # NEX
fishers <- read_csv(paste0("./data/02_data/2.1_nex_ex_", sim, ".csv")) # comprable EX for NEX
```

# Wrangle data
dat: contains a row for  (nrow(dat)) = every available option (n grid cells, excluding current sz and sim sz with no recreational value) * per trip (n trips). The choice column indicated what site the recreator actually chose. 
```{r rearrange, include = FALSE}
    b %<>% rename(cov = ...1) %>% 
      mutate(cov = ifelse(Vars %in% "age", paste0(cov, "_", Vars), cov)) %>% 
      mutate(cov = ifelse(!(Vars %in% c("_cons", "age")), Vars, cov)) %>% 
      dplyr::select(-Vars)
  
    v %<>% 
      # mutate(x...1 = ifelse(x...2 %in% "travelcost", "tc", x...1)) %>%  
      mutate(x...1 = ifelse(x...2 %in% "age", paste0(x...1, "_", x...2), x...1)) %>% 
      mutate(x...1 = ifelse(!(x...2 %in% c("_cons", "age")), x...2, x...1)) %>%  
      dplyr::select(-x...2) %>% 
      distinct()

    colnames(v) <- c("vars", v$x...1)
    v %<>% dplyr::select(-vars)
    vars <- b$cov #use

    #'[#VALIDATE: TRUE/TRUE/check min and max, extreme values will skew model (issue 2.1?)]
    nrow(b) == length(v) # should be true
    length(v) == nrow(v) # should be true
    summary(b$Coef) # check min and max, the more extreme the values the more inflated or deflated the results will be. Most likely a problem with script 2.1 or model.
    
    tau <- b[86:89, ]
    tau %<>% mutate(cov = substr(cov, 1, 3)) 
    tau %<>% rename(cset = cov, tau = Coef) 
    dat %<>% left_join(tau)
    
    b_asc <- b[c(1, 5:85),]
    b_nest <- b[2:4,]
    
    v_asc <- v[c(1, 5:85),]
    v_asc <- v_asc %>% dplyr::select(-contains("age") & -contains("tau"))
    
    v_nest <- v[2:4,]
    v_nest <- v_nest %>% dplyr::select(contains("age"))
```

The coef of the logit model gives us the marginal utilities. This is the extra utility an agent receives for one extra unit, given all the other parameters stay constant. 

Calculate the utility (Vj) for every alternative, each individual observation in dat represents an alternative. 

We expect recreator  (n) to choose the site (j) with the highest expected utility. The utility  (Vj) of a site is a function of the observed attributes (B) of those sites and associated error (e).

      Vnj = Bj + Ej

      Vj = B(depth + travel cost etc.) + e 
      
The errors are assumed to follow the generalized extreme value (GEV) distribution type 1 (Gumbel distribution). This distribution is a normal distribution with a slight larger tail on one side. The errors are also assumed to be identical and independently distributed (i.i.d. assumption). This means there cannot be any correlation in the errors. Therefore the site definitions have to have no correlated errors, and therefore have to be different enough that the error don't correlated. If the researcher thinks there is some unobserved correlation in the errors, then the alternatives can be grouped into nests. For example boat fishing and shore fishing and inherently different, therefore you could cluster shore and boat based sites into a boat and shore nest. Doing a nested model relaxes the iid assumption and allows for some correlation within nests, but no correlation between nests. 



# Status Quo
```{r}
## Generate error from cov-var matrix
    n1 <- 1000 # number of samples (all estimates)
    mvn_b <- mvrnorm(n1, mu = b_asc$Coef, Sigma = as.matrix(v_asc))  # generate error
    dim(mvn_b)[1] == n1 # should be true
    
## Make rum matirx which alings with b cov
    b_asc %<>% mutate(cov = ifelse(!str_detect(cov, "fc"), paste0("gridid_", cov), cov)) # make names the same
    bid <- unique(b_asc$cov) 
    rum_matrix <- as.matrix(dat[, bid]) # extract data 
      
## Calc utility
    vj_bl <- matrix(NA, nrow = nrow(rum_matrix), ncol = n1) # create an empty utility matrix
        
    for (i in 1:n1) { 
        vj_bl[ ,i] <- as.vector(rum_matrix %*% as.matrix(mvn_b[i,]))  
        }
        
    which(is.infinite(as.matrix(vj_bl)))
    
## Conditional Probability
   tau <- as.vector(dat$tau)
   condp_num <- exp(vj_bl/tau)
   
    dat %<>%
        mutate(gridid_int = group_indices(., gridid_alt),
               tripid_int = as.integer(trip_id),
               cset_int = group_indices(., cset))  # making id integers
    
   condp_num <- as.data.table(condp_num) # make data.table to save RAM
   condp_num_cols <- colnames(condp_num) # save the names of the draws for later
   condp_num$trip <- as.integer(dat$tripid_int) # add 
   condp_num$cset <- as.integer(dat$cset_int) # add 
   condp_num$gridid <- as.integer(dat$gridid_int) # add 
   
   condp_num %<>%  relocate(gridid, .before = 1)
   condp_num %<>%  relocate(cset, .before = 1)
   condp_num %<>%  relocate(trip, .before = 1)
  # 
  # condp_dom <- condp_num %>%
  #   group_by(trip, cset) %>%
  #   summarise(across(V1:V1000, sum)) %>%
  #   rename_with(~ gsub("V", "dom_", .), starts_with("V"))
  
  condp_dom <- condp_num[ , lapply(.SD, sum), by = c("trip", "cset"), .SDcols = condp_num_cols]
  
  condp_dom %<>% left_join(condp_num, by = c("trip", "cset"))
  condp_dom %<>% dplyr::select(1:1002) 

  condp <- as.matrix(condp_num[,4:1003])/as.matrix(condp_dom[,3:1002])
  
  dat$lci_condp <- rowQuantiles(condp, probs = sqrt(0.025)) # lower ci
  dat$m_condp <- rowQuantiles(condp, probs = sqrt(0.5)) # lower ci
  dat$uci_condp <- rowQuantiles(condp, probs = 1 - sqrt(0.025)) # upper ci
  
  iv <- log(condp_dom[,3:1002])
  
  which(dat$lci_condp > dat$m_condp)
  which(dat$m_condp > dat$uci_condp)
  
# P1: Pr that agent chooses nest
## utility of nest
    n1 <- 1000 # number of samples (all estimates)
    mvn_bk <- mvrnorm(n1, mu = b_nest$Coef, Sigma = as.matrix(v_nest))  # generate error
    dim(mvn_bk)[1] == n1 # should be true
    
## Make rum matirx which alings with b co
    dat %<>% mutate(b_n_age = ifelse(dat$cset %in% "b_n", dat$age, 0),
                    s_e_age = ifelse(dat$cset %in% "s_e", dat$age, 0),
                    s_n_age = ifelse(dat$cset %in% "s_n", dat$age, 0))
    
    rum_matrix <- as.matrix(dat[, c("b_n_age", "s_e_age", "s_n_age")]) # extract data 
    
      
## Calc utility
    vj_k <- matrix(NA, nrow = nrow(rum_matrix), ncol = n1) # create an empty utility matrix
        
    for (i in 1:n1) { 
        vj_k[ ,i] <- as.vector(rum_matrix %*% as.matrix(mvn_bk[i,]))  
        }
        
    which(is.infinite(as.matrix(vj_k)))
  
  iv <- iv*tau
  
  p1_num <- exp(vj_k+iv)
  
  p1_num <- as.data.table(p1_num)
  p1_cols <- colnames(p1_num)
  p1_num$trip <- as.integer(dat$tripid_int)
  
  # p1_dom <- p1_num %>% 
  #   group_by(trip) %>% 
  #   summarise(across(1:1000, sum))
  # 
   p1_dom <- p1_num[ , lapply(.SD, sum), by = trip, .SDcols = p1_cols]  # BOAT BASED

  # Use this to find p1, but you will need to change it so it deosnt chnage the current p1_dom  
  # p1_dom %<>%  left_join(p1_num, by = "trip")
  # p1_dom %<>% dplyr::select(1:1001) 
  # 
  # p1_num <- as.matrix(p1_num[,2:1001])
  # p1_dom <- as.matrix(p1_dom[,2:1001])
  # 
  # p1 = p1_num/p1_dom
  # 
  # dat$lci_p1 <- rowQuantiles(p1, probs = sqrt(0.025)) # lower ci
  # dat$m_p1 <- rowQuantiles(p1, probs = sqrt(0.5)) # lower ci
  # dat$uci_p1 <- rowQuantiles(p1, probs = 1 - sqrt(0.025)) # upper ci
  
  # which(dat$lci_p1 > dat$m_p1)
  # which(dat$m_p1 > dat$uci_p1)
```

# Counterfactual
```{r}
## Utility - turn utility to zero where sz are being removed
  vj_bl_sim <- as.data.table(vj_bl) # use base bl utility matirx
  cols <- colnames(vj_bl_sim)
  vj_bl_sim$gridid_int <- dat$gridid_int # append gridids

  ntz <- dat %>% filter(zone_rm == 1) 
  ntz <- unique(ntz$gridid_int)
  
   vj_bl_sim[vj_bl_sim$gridid_int %in% ntz, cols] <- 0
        
   which(is.infinite(as.matrix(vj_bl_sim)))
    
## Conditional Probability
   vj_bl_sim <- vj_bl_sim[,1:1000] # remove gridid_int
   
   condp_num_sim <- exp(vj_bl_sim/tau)
    
   condp_num_sim <- as.data.table(condp_num_sim) # make data.table to save RAM
   condp_num_sim_cols <- colnames(condp_num_sim) # save the names of the draws for later
   condp_num_sim$trip <- as.integer(dat$tripid_int) # add 
   condp_num_sim$cset <- as.integer(dat$cset_int) # add 
   
   condp_num_sim %<>%  relocate(cset, .before = 1)
   condp_num_sim %<>%  relocate(trip, .before = 1)
   
  # condp_dom_sim <- condp_num_sim %>% 
  #   group_by(trip, cset) %>% 
  #   summarise(across(V1:V1000, sum)) %>% 
  #   rename_with(~ gsub("V", "dom_", .), starts_with("V"))
   
   condp_dom_sim <- condp_num_sim[ , lapply(.SD, sum), by = c("trip", "cset"), .SDcols = condp_num_sim_cols]
    
  condp_dom_sim %<>% left_join(condp_num_sim, by = c("trip", "cset"))
  condp_dom_sim %<>% dplyr::select(1:1002) 

  condp_sim <- as.matrix(condp_num_sim[,3:1002])/as.matrix(condp_dom_sim[,3:1002])
  
  dat$lci_condp_sim <- rowQuantiles(condp_sim, probs = sqrt(0.025)) # lower ci
  dat$m_condp_sim <- rowQuantiles(condp_sim, probs = sqrt(0.5)) # lower ci
  dat$uci_condp_sim <- rowQuantiles(condp_sim, probs = 1 - sqrt(0.025)) # upper ci
  
  iv_sim <- log(condp_dom_sim[,3:1002])
  
  which(dat$lci_condp_sim > dat$m_condp_sim)
  which(dat$m_condp_sim > dat$uci_condp_sim)
  
# P1: Pr that agent chooses nest
  iv_sim <- iv_sim*tau
  p1_num_sim <- exp(vj_k+iv_sim)
  p1_num_sim <- as.data.table(p1_num_sim)
  p1_cols <- colnames(p1_num_sim)
  p1_num_sim$trip <- as.integer(dat$trip_id)
  
  # p1_dom_sim <- p1_num_sim %>% 
  #   group_by(trip) %>% 
  #   summarise(across(1:1000, sum))

   p1_dom_sim <- p1_num_sim[ , lapply(.SD, sum), by = trip, .SDcols = p1_cols]
    
  # p1_dom_sim %<>%  left_join(p1_num_sim, by = "trip")
  # p1_dom_sim %<>% dplyr::select(1:1001) 
  # 
  # p1_num_sim <- as.matrix(p1_num_sim[,2:1001])
  # p1_dom_sim <- as.matrix(p1_dom_sim[,2:1001])
  # 
  # p1_sim = p1_num_sim/p1_dom_sim
  # 
  # dat$lci_p1_sim <- rowQuantiles(p1_sim, probs = sqrt(0.025)) # lower ci
  # dat$m_p1_sim <- rowQuantiles(p1_sim, probs = sqrt(0.5)) # lower ci
  # dat$uci_p1_sim <- rowQuantiles(p1_sim, probs = 1 - sqrt(0.025)) # upper ci
  # 
  # iv_p1_sim <- log(p1_dom_sim)
  # 
  # which(dat$lci_p1_sim > dat$m_p1_sim)
  # which(dat$m_p1_sim > dat$uci_p1_sim)
```

# Welfare
```{r}
b_fishers <- dat %>% filter(trip_id %in% fishers$trip_id)

# Extracting the welfare impact
    W <- log(p1_dom_sim[, -1]) -  log(p1_dom[, -1]) # always subtract the status quo by the counterfactual (simulation)
    W <- t(W)/mvn_b[ ,1] # divide the logsums by the travel cost (need to pivot to do this t())
    W <- t(W) # pivot back to original orientation
    
# Summaries across draws
    W <- as.matrix(W)
    
    p1_dom_sim$lci_w <- rowQuantiles(W, probs = sqrt(0.025)) # lower ci
    p1_dom_sim$m_w <- rowQuantiles(W, probs = sqrt(0.5)) # median
    p1_dom_sim$uci_w <- rowQuantiles(W, probs = 1 - sqrt(0.025)) # upper ci
    
    dat %<>% left_join(p1_dom_sim[ , c("trip", "lci_w", "m_w", "uci_w")], by = c("tripid_int" = "trip")) 
    
    w <- dat %>% distinct(trip_id, .keep_all = TRUE)
    w %<>% mutate(fisher = ifelse(trip_id %in% fishers$trip_id, 1, 0)) 
    w %<>% group_by(fisher) %>% summarise(lci = round(mean(lci_w), 2), mean = round(mean(m_w), 2), uci = round(mean(uci_w), 2))

    w
```

# ARCHIVE
## 3 values 
 If you manged to find out how to extract the correct confidence intervals  so you only have 3 values. 

### Wrangle
The data is in the form of the model output from stata and is formatted like a table. 
```{r rearrange, include = FALSE}
# b %<>%
#   rename(cov = "fchoice",
#          coef = "Coefficient",
#          stdp = "Std. err.",
#          z_stat = "z",
#          p_value = "P>|z|",
#          lci = "[95% conf. interval]",
#          uci = "...7") # rename model output table
# 
# b %<>% mutate(cov = ifelse(cov == "_cons", lag(cov), cov)) # filling gaps in cov with correct gridid
# b %<>% filter(rowSums(is.na(.)) <= 2) # filter rows you dont need
# b %<>% mutate(cov = ifelse(str_detect(cov, "tau"), substr(cov, 1, 3), cov)) # change name of taus to match dat
# 
# asc <- b[2:82,] # isolate ASCs: one less that you would expect because base is missing
# dat %<>% left_join(asc, by = c("gridid_alt" = "cov")) # append ASCs
# dat %<>% mutate_at(vars(coef, lci, uci), ~ ifelse(is.na(.), 0, .))
# 
# tau <- b[83:86,] # isolate taus
# tau %<>%
#   dplyr::select(-c(3:5)) %>%
#   rename(cset = cov, tau = coef, lci_tau = lci, uci_tau = uci)
# dat %<>% left_join(tau, by = "cset")  # append taus
# 
# # b$coef[1] <- -3
# dat %<>% mutate(lci_tc = b$lci[1],
#                 tc = b$coef[1],
#                 uci_tc = b$uci[1]) # appending tc coef to data
# 
# # dat[which(dat$trip_id %in% 259), c("cset", "gridid_alt", "coef", "lci", "uci", "tau", "lci_tau", "uci_tau", "tc", "lci_tc", "uci_tc")]
```

### Base
```{r}
# calculate utility of tc
dat %<>%
  mutate(lci_vj_tc = lci_tc * fcflt_spgam,
         vj_tc = tc * fcflt_spgam,
         uci_vj_tc = uci_tc * fcflt_spgam)

any(dat$lci_vj_tc > dat$vj_tc) # FALSE
any(dat$uci_vj_tc < dat$vj_tc) # FALSE

# calculate total utility
dat %<>%
  mutate(lci_tot_vj = lci_vj_tc + coef,
         tot_vj = vj_tc + coef,
         uci_tot_vj = uci_vj_tc + coef)

any(dat$lci_tot_vj > dat$tot_vj) # FALSE
any(dat$uci_tot_vj < dat$tot_vj) # FALSE

# Conditional probability
## condp scalar
dat %<>%
  mutate(lci_condp_scale = lci_tot_vj/lci_tau,
         condp_scale = tot_vj/tau, 
         uci_condp_scale = uci_tot_vj/uci_tau)

any(dat$lci_condp_scale > dat$condp_scale) # TRUE
any(dat$uci_condp_scale < dat$condp_scale) # TRUE

## condp numerator
dat %<>%
  mutate(lci_condp_num = exp(lci_condp_scale),
         condp_num = exp(condp_scale), 
         uci_condp_num = exp(uci_condp_scale))

any(dat$lci_condp_num > dat$condp_num) # TRUE
any(dat$uci_condp_num < dat$condp_num) # FALSE

## condp denominator
tmp <- dat %>% group_by(trip_id, cset) %>% summarise(lci_condp_dom = sum(lci_condp_num)) %>% ungroup()
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id, cset) %>% summarise(condp_dom = sum(condp_num)) %>% ungroup()
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id, cset) %>% summarise(uci_condp_dom = sum(uci_condp_num)) %>% ungroup()
dat %<>% left_join(tmp) 

any(dat$lci_condp_dom > dat$condp_dom) # TRUE
any(dat$uci_condp_dom < dat$condp_dom) # FALSE

# condp
dat %<>%
  mutate(lci_condp = lci_condp_num/lci_condp_dom,
         condp = condp_num/condp_dom, 
         uci_condp = uci_condp_num/uci_condp_dom)

any(dat$lci_condp > dat$condp) # TRUE
any(dat$uci_condp < dat$condp) # TRUE

# condp iv (inclusive value of condp)
dat %<>%
  mutate(lci_iv = log(lci_condp_dom),
         iv = log(condp_dom), 
         uci_iv = log(uci_condp_dom))

any(dat$lci_iv > dat$iv) # TRUE
any(dat$uci_iv < dat$iv) # FALSE

# P1: probability of chooses nest
## p1 scalar
dat %<>%
  mutate(lci_p1_scale = lci_iv*lci_tau,
         p1_scale = iv*tau,
         uci_p1_scale = uci_iv*uci_tau)

any(dat$lci_p1_scale > dat$p1_scale) # FALSE
any(dat$uci_p1_scale < dat$p1_scale) # FALSE

## p1 numerator
dat %<>%
  mutate(lci_p1_num = exp(lci_p1_scale),
         p1_num = exp(p1_scale), 
         uci_p1_num = exp(uci_p1_scale))

any(dat$lci_p1_num > dat$p1_num) # FALSE
any(dat$uci_p1_num < dat$p1_num) # FALSE

# p1 denominator
tmp <- dat %>% group_by(trip_id) %>% distinct(lci_p1_num) %>% summarise(lci_p1_dom = sum(lci_p1_num))
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id) %>% distinct(p1_num) %>% summarise(p1_dom = sum(p1_num))
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id) %>% distinct(uci_p1_num) %>% summarise(uci_p1_dom = sum(uci_p1_num))
dat %<>% left_join(tmp) 

any(dat$lci_p1_dom > dat$p1_dom) # FALSE
any(dat$uci_p1_dom < dat$p1_dom) # FALSE

# p1
dat %<>%
  mutate(lci_p1 = lci_p1_num/lci_p1_dom,
         p1 = p1_num/p1_dom,
         uci_p1 = uci_p1_num/uci_p1_dom)

any(dat$lci_p1 > dat$p1) # TRUE
any(dat$uci_p < dat$p1) # FALSE

## P2: pr that agent will choose bottom level alternative
dat %<>%
  mutate(lci_p2 = lci_condp * lci_p1,
         p2 = condp * p1, 
         uci_p2 = uci_condp * uci_p1)

any(dat$lci_p2 > dat$p2) # TRUE
any(dat$uci_p2 < dat$p2) # TRUE

# Logsum base
dat %<>%
  mutate(lci_logsum_base = log(lci_p1_dom),
         logsum_base = log(p1_dom), 
         uci_logsum_base = log(uci_p1_dom))

any(dat$lci_logsum_base > dat$logsum_base) # FALSE
any(dat$uci_logsum_base < dat$logsum_base) # FALSE

# dat[which(dat$trip_id == 259), c(1, 45, 213:214, 223, 228:length(dat))]
```

### Counterfactual 
```{r}
# Change utility to zero for fishers
dat$lci_vj_sim <- dat$lci_tot_vj
dat$vj_sim <- dat$tot_vj
dat$uci_vj_sim <- dat$uci_tot_vj

identical(dat$lci_vj_sim, dat$lci_tot_vj) # TRUE
identical(dat$vj_sim, dat$tot_vj) # TRUE
identical(dat$uci_vj_sim, dat$uci_tot_vj) # TRUE

# dat %<>% mutate(lci_vj_sim = ifelse(zone_rm == 1, 0, lci_vj_sim)) 
# dat %<>% mutate(vj_sim = ifelse(zone_rm == 1, 0, vj_sim)) 
# dat %<>% mutate(uci_vj_sim = ifelse(zone_rm == 1, 0, uci_vj_sim)) 

dat %<>% filter(zone_rm == 0)

identical(dat$lci_vj_sim, dat$lci_tot_vj) # FALSE
identical(dat$vj_sim, dat$tot_vj) # FALSE
identical(dat$uc_vj_sim, dat$uci_tot_vj) # FALSE

# Conditional probability
## condp scalar
dat %<>%
  mutate(lci_condp_scale_sim = lci_vj_sim/lci_tau,
         condp_scale_sim = vj_sim/tau, 
         uci_condp_scale_sim = uci_vj_sim/uci_tau)

any(dat$lci_condp_scale_sim > dat$condp_scale_sim) # TRUE
any(dat$uci_condp_scale_sim < dat$condp_scale_sim) # TRUE

## condp numerator
dat %<>%
  mutate(lci_condp_num_sim = exp(lci_condp_scale_sim),
         condp_num_sim = exp(condp_scale_sim), 
         uci_condp_num_sim = exp(uci_condp_scale_sim))

any(dat$lci_condp_num_sim > dat$condp_num_sim) # TRUE
any(dat$uci_condp_num_sim < dat$condp_num_sim) # TRUE

## condp denominator
tmp <- dat %>% group_by(trip_id, cset) %>% summarise(lci_condp_dom_sim = sum(lci_condp_num_sim)) %>% ungroup()
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id, cset) %>% summarise(condp_dom_sim = sum(condp_num_sim)) %>% ungroup()
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id, cset) %>% summarise(uci_condp_dom_sim = sum(uci_condp_num_sim)) %>% ungroup()
dat %<>% left_join(tmp) 

any(dat$lci_condp_dom_sim > dat$condp_dom_sim) # TRUE
any(dat$uci_condp_dom_sim < dat$condp_dom_sim) # TRUE

# condp
dat %<>%
  mutate(lci_condp_sim = lci_condp_num_sim/lci_condp_dom_sim,
         condp_sim = condp_num_sim/condp_dom_sim, 
         uci_condp_sim = uci_condp_num_sim/uci_condp_dom_sim)

any(dat$lci_condp_sim > dat$condp_sim) # TRUE
any(dat$uci_condp_sim < dat$condp_sim) # TRUE

# condp iv (inclusive value of condp)
dat %<>%
  mutate(lci_iv_sim = log(lci_condp_dom_sim),
         iv_sim = log(condp_dom_sim), 
         uci_iv_sim = log(uci_condp_dom_sim))

any(dat$lci_iv_sim > dat$iv_sim) # TRUE
any(dat$uci_iv_sim < dat$iv_sim) # TRUE

# P1: probability of chooses nest
## p1 scalar
dat %<>%
  mutate(lci_p1_scale_sim = lci_iv_sim*lci_tau,
         p1_scale_sim = iv_sim*tau,
         uci_p1_scale_sim = uci_iv_sim*uci_tau)

any(dat$lci_p1_scale_sim > dat$p1_scale_sim) # FALSE
any(dat$uci_p1_scale_sim < dat$p1_scale_sim) # FALSE

## p1 numerator
dat %<>%
  mutate(lci_p1_num_sim = exp(lci_p1_scale_sim),
         p1_num_sim = exp(p1_scale_sim), 
         uci_p1_num_sim = exp(uci_p1_scale_sim))

any(dat$lci_p1_num_sim > dat$p1_num_sim) # FALSE
any(dat$uci_p1_num_sim < dat$p1_num_sim) # FALSE

# p1 denominator
tmp <- dat %>% group_by(trip_id) %>% distinct(lci_p1_num_sim) %>% summarise(lci_p1_dom_sim = sum(lci_p1_num_sim))
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id) %>% distinct(p1_num_sim) %>% summarise(p1_dom_sim = sum(p1_num_sim))
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id) %>% distinct(uci_p1_num_sim) %>% summarise(uci_p1_dom_sim = sum(uci_p1_num_sim))
dat %<>% left_join(tmp) 

any(dat$lci_p1_dom_sim > dat$p1_dom_sim) # FALSE
any(dat$uci_p1_dom_sim < dat$p1_dom_sim) # FALSE

# p1
dat %<>%
  mutate(lci_p1_sim = lci_p1_num_sim/lci_p1_dom_sim,
         p1_sim = p1_num_sim/p1_dom_sim,
         uci_p1_sim = uci_p1_num_sim/uci_p1_dom_sim)

any(dat$lci_p1_sim > dat$p1_sim) # TRUE
any(dat$uci_p_sim < dat$p1_sim) # FALSE

## P2: pr that agent will choose bottom level alternative
dat %<>%
  mutate(lci_p2_sim = lci_condp_sim * lci_p1_sim,
         p2_sim = condp_sim * p1_sim, 
         uci_p2_sim = uci_condp_sim * uci_p1_sim)

any(dat$lci_p2_sim > dat$p2_sim) # TRUE
any(dat$uci_p2_sim < dat$p2_sim) # TRUE

# Logsum base
dat %<>%
  mutate(lci_logsum_sim = log(lci_p1_dom_sim),
         logsum_sim = log(p1_dom_sim), 
         uci_logsum_sim = log(uci_p1_dom_sim))

any(dat$lci_logsum_sim > dat$logsum_sim) # FALSE
any(dat$uci_logsum_sim < dat$logsum_sim) # FALSE

dat[which(dat$trip_id == 259), c(1, 45, 213:214, 223, 229:231, 274:length(dat))]
```

### Welfare estimate
```{r}
b_fishers <- dat %>% filter(trip_id %in% fishers$trip_id)

tmp <- dat %>% group_by(trip_id) %>% summarise(logsum_base2 = sum(p1_dom))
tmp %<>% mutate(logsum_base2 = log(logsum_base2)) 
dat %<>% left_join(tmp) 

tmp <- dat %>% group_by(trip_id) %>% summarise(logsum_sim2 = sum(p1_dom_sim))
tmp %<>% mutate(logsum_sim2 = log(logsum_sim2)) 
dat %<>% left_join(tmp) 

a <- dat %>% group_by(trip_id) %>% 
  summarise(sub = logsum_sim2 - logsum_base2,
            w = sub/b$coef[1]) 
  
b$coef[1]

a %<>% distinct(trip_id, .keep_all = TRUE) 

a %<>% mutate(fisher = ifelse(trip_id %in% fishers$trip_id, 1, 0)) 
a %<>% group_by(fisher) %>% summarise(mean = mean(w))

# mean(a$w)
# 
# b_fishers %<>% 
#   mutate(av_lci_w = mean(lci_w),
#          av_w = mean(w),
#          av_uci_w = mean(uci_w))
#   
# any(dat$av_lci_w > dat$av_w) # FALSE
# any(dat$av_uci_w < dat$av_w) # FALSE
  
## Welfare estimates
# cs <- cbind(b_fishers[1, "av_lci_w"], b_fishers[1, "av_w"], b_fishers[1, "av_uci_w"])

# dat[which(dat$trip_id == 259), c(1, 45, 213:214, 223, 271:273, 307:length(dat))]
# 
# dat %>% filter(zone_rm == 1) %>% group_by(gridid_alt) %>% summarise(n=n())

# which(dat$choice == 1 & dat$cset %in% "s_n" & dat$boat_access %in% "Yes")

# dat[which(dat$trip_id == 279), c("cset", "gridid_alt","choice", "zone_rm","tot_vj", "vj_sim", "boat_access")]
```

## Base without error
```{r}
# tmp <- dat %>% 
#   group_by(trip_id) %>% 
#   summarise(lci_logsum_base = mean(lci_logsum_base),
#             mean_logsum_base = mean(logsum_base),
#             uci_logsum_base = mean(uci_logsum_base))

# dat$vj_tc <- dat$fcflt_spgam * dat$tc_coef # utility of tc
# dat$vj_tot <- dat$vj_tc + dat$Coef # total utility

# Conditional probability
# dat$condp_scale <- dat$vj_tot/dat$tau 
# dat$condp_num <- exp(dat$condp_scale)
# tmp <- dat %>% group_by(trip_id, cset) %>% summarise(condp_dom = sum(condp_num)) %>% ungroup()
# dat %<>% left_join(tmp) 
# dat$condp <- dat$condp_num/dat$condp_dom
# dat$iv <- log(dat$condp_dom)

## P1: probability of choosen nest
# dat$p1_scale <- dat$iv*dat$tau
# Wnk: THIS IS WHERE YOU WOUDL ADD THE UTILITY FOR VARS THAT DESCRIBE YOUR NEST AND ADD IT TO p1_scale
# I do not have any in this model
# dat$p1_num <- exp(dat$p1_scale)
# tmp <- dat %>% group_by(trip_id) %>% distinct(p1_num) %>% summarise(p1_dom = sum(p1_num))
# dat %<>% left_join(tmp) 
# dat$p1 <- dat$p1_num/dat$p1_dom

# dat$p2 <- dat$condp * dat$p1

## logsum_base
# logsum_base <- log(dat$p1_dom)
```








